{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# ü§ñ Assistente Virtual H√≠brido (IA + Comandos Locais)\n",
    "\n",
    "Este notebook apresenta a implementa√ß√£o de um assistente virtual modular. Ele combina o poder de modelos de linguagem de larga escala (LLMs) com funcionalidades locais de automa√ß√£o.\n",
    "\n",
    "### üåü Funcionalidades Principais:\n",
    "- **STT (Speech to Text)**: Reconhecimento de fala local utilizando o modelo **OpenAI Whisper**.\n",
    "- **TTS (Text to Speech)**: S√≠ntese de voz offline atrav√©s da biblioteca **pyttsx3**.\n",
    "- **IA (C√©rebro)**: Integra√ß√£o com o modelo **GLM-4.7-Flash** via Hugging Face Router.\n",
    "- **Automa√ß√£o Local**: Comandos diretos para Wikipedia, YouTube e busca por servi√ßos pr√≥ximos (ex: farm√°cias)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install_md",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Passo 1: Instala√ß√£o de Depend√™ncias\n",
    "\n",
    "Antes de come√ßar, precisamos garantir que todas as bibliotecas necess√°rias estejam instaladas no ambiente. Este bloco detecta depend√™ncias ausentes e as instala automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install_deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Depend√™ncias j√° est√£o configuradas no ambiente.\n"
     ]
    }
   ],
   "source": [
    "# Verifica√ß√£o e instala√ß√£o autom√°tica de depend√™ncias\n",
    "try:\n",
    "    # Tenta importar as bibliotecas principais para checar se existem\n",
    "    import openai\n",
    "    import whisper\n",
    "    import sounddevice\n",
    "    import pyttsx3\n",
    "    import dotenv\n",
    "    print(\"‚úÖ Depend√™ncias j√° est√£o configuradas no ambiente.\")\n",
    "except ImportError:\n",
    "    # Caso alguma falhe, inicia a instala√ß√£o via pip\n",
    "    print(\"‚è≥ Algumas depend√™ncias n√£o foram encontradas. Instalando... (isso pode levar alguns minutos)\")\n",
    "    # Bibliotecas:\n",
    "    # - openai: Interface para a API da IA\n",
    "    # - openai-whisper: Modelo de transcri√ß√£o de √°udio local\n",
    "    # - sounddevice & scipy: Captura e processamento de √°udio do microfone\n",
    "    # - pyttsx3: Motor de s√≠ntese de voz offline\n",
    "    # - python-dotenv: Carregamento de chaves de API de arquivos .env\n",
    "    %pip install openai openai-whisper sounddevice scipy pyttsx3 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_md",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Passo 2: Importa√ß√µes e Configura√ß√µes\n",
    "\n",
    "Importamos os m√≥dulos do Python e carregamos as vari√°veis de ambiente (como o token do Hugging Face)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√≥dulos importados e configura√ß√µes de ambiente carregadas.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from typing import Protocol, Optional, Iterable\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as configura√ß√µes do arquivo .env (Token da API, etc.)\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ M√≥dulos importados e configura√ß√µes de ambiente carregadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protocols_md",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Passo 3: Defini√ß√£o de Interfaces (Protocolos)\n",
    "\n",
    "Para manter o c√≥digo organizado e modular, definimos interfaces para o Reconhecimento de Voz (STT) e S√≠ntese de Voz (TTS). Isso permite trocar as tecnologias sem alterar a l√≥gica principal do assistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protocols",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechToText(Protocol):\n",
    "    \"\"\"Interface para componentes que convertem fala em texto.\"\"\"\n",
    "    def listen(self, timeout: Optional[float] = None) -> Optional[str]:\n",
    "        \"\"\"Ouve o √°udio e retorna a string transcrita ou None.\"\"\"\n",
    "        pass\n",
    "\n",
    "class TextToSpeech(Protocol):\n",
    "    \"\"\"Interface para componentes que convertem texto em fala.\"\"\"\n",
    "    def speak(self, text: str) -> None:\n",
    "        \"\"\"Processa a string de texto e emite o som correspondente.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stt_md",
   "metadata": {},
   "source": [
    "## üéôÔ∏è Passo 4: Implementa√ß√£o do STT (Escuta)\n",
    "\n",
    "Implementamos duas formas de entrada: \n",
    "1. **WhisperSTT**: Usa o microfone e o modelo local do Whisper.\n",
    "2. **TextInputSTT**: Permite interagir via teclado (ideal para depura√ß√£o ou ambientes sem microfone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stt_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhisperSTT:\n",
    "    \"\"\"Reconhecimento de fala local usando OpenAI Whisper.\"\"\"\n",
    "    def __init__(self, model_size: str = \"base\", language: str = \"pt\", duration: int = 5):\n",
    "        \"\"\"\n",
    "        Inicializa o modelo Whisper.\n",
    "        :param model_size: Tamanho do modelo (base, tiny, small, etc.)\n",
    "        :param language: Idioma para transcri√ß√£o\n",
    "        :param duration: Tempo padr√£o de grava√ß√£o em segundos\n",
    "        \"\"\"\n",
    "        # Importa√ß√µes internas para carregar apenas se necess√°rio\n",
    "        import whisper\n",
    "        import sounddevice as sd\n",
    "        import scipy.io.wavfile as wav\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        self._whisper = whisper\n",
    "        self._sd = sd\n",
    "        self._wav = wav\n",
    "        self._tempfile = tempfile\n",
    "        self._os = os\n",
    "        \n",
    "        # Carrega o modelo na mem√≥ria\n",
    "        print(f\"‚è≥ Carregando modelo Whisper '{model_size}'...\")\n",
    "        self._model = whisper.load_model(model_size)\n",
    "        self._language = language\n",
    "        self._duration = duration\n",
    "\n",
    "    def listen(self, timeout: Optional[float] = None) -> Optional[str]:\n",
    "        \"\"\"Grava o microfone e transcreve o √°udio para texto.\"\"\"\n",
    "        duration = timeout if timeout is not None else self._duration\n",
    "        fs = 44100  # Frequ√™ncia de amostragem\n",
    "        \n",
    "        print(f\"\\nüé§ [Escutando...] Fale agora ({duration}s).\")\n",
    "        \n",
    "        try:\n",
    "            # Grava √°udio do dispositivo de entrada padr√£o\n",
    "            recording = self._sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "            self._sd.wait()  # Espera a grava√ß√£o terminar\n",
    "            print(\"‚è≥ [Processando...]\")\n",
    "            \n",
    "            # Salva em um arquivo tempor√°rio para processamento do Whisper\n",
    "            with self._tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "                temp_filename = f.name\n",
    "            \n",
    "            self._wav.write(temp_filename, fs, recording)\n",
    "            \n",
    "            # Transcri√ß√£o\n",
    "            result = self._model.transcribe(temp_filename, language=self._language, fp16=False)\n",
    "            text = result[\"text\"].strip()\n",
    "            \n",
    "            # Limpeza do arquivo tempor√°rio\n",
    "            try:\n",
    "                self._os.remove(temp_filename)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            return text if text else None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro no processamento de √°udio: {e}\")\n",
    "            return None\n",
    "\n",
    "class TextInputSTT:\n",
    "    \"\"\"Simula reconhecimento de fala atrav√©s de entrada de texto no console.\"\"\"\n",
    "    def __init__(self, inputs: Optional[Iterable[str]] = None):\n",
    "        self._inputs = list(inputs) if inputs is not None else None\n",
    "\n",
    "    def listen(self, timeout: Optional[float] = None) -> Optional[str]:\n",
    "        \"\"\"L√™ do teclado ou de uma lista pr√©-definida de comandos.\"\"\"\n",
    "        if self._inputs is not None:\n",
    "            if not self._inputs: return None\n",
    "            return self._inputs.pop(0)\n",
    "        try:\n",
    "            return input(\"\\n‚å®Ô∏è Digite seu comando (ou 'sair'): \").strip()\n",
    "        except EOFError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tts_md",
   "metadata": {},
   "source": [
    "## üîä Passo 5: Implementa√ß√£o do TTS (Fala)\n",
    "\n",
    "Configuramos a sa√≠da de voz. O **Pyttsx3TTS** utiliza as vozes instaladas no sistema operacional, funcionando totalmente offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tts_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pyttsx3TTS:\n",
    "    \"\"\"S√≠ntese de voz offline usando pyttsx3.\"\"\"\n",
    "    def __init__(self, language: str = \"pt-BR\", rate: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Inicializa o motor de voz.\n",
    "        :param language: Prefixo do idioma (ex: pt)\n",
    "        :param rate: Velocidade da fala\n",
    "        \"\"\"\n",
    "        import pyttsx3\n",
    "        self._engine = pyttsx3.init()\n",
    "        self._language = language\n",
    "        \n",
    "        if rate is not None:\n",
    "            self._engine.setProperty(\"rate\", rate)\n",
    "            \n",
    "        self._select_voice()\n",
    "\n",
    "    def _select_voice(self) -> None:\n",
    "        \"\"\"Busca no sistema uma voz compat√≠vel com o idioma escolhido.\"\"\"\n",
    "        voices = self._engine.getProperty(\"voices\")\n",
    "        chosen = None\n",
    "        for v in voices:\n",
    "            name = getattr(v, \"name\", \"\") or \"\"\n",
    "            lang = \"\".join(getattr(v, \"languages\", []) or [])\n",
    "            # Verifica se o idioma ou nome da voz cont√©m o c√≥digo do idioma (ex: pt)\n",
    "            if self._language.lower()[:2] in (lang.lower(), name.lower()):\n",
    "                chosen = v.id\n",
    "                break\n",
    "        if chosen:\n",
    "            self._engine.setProperty(\"voice\", chosen)\n",
    "\n",
    "    def speak(self, text: str) -> None:\n",
    "        \"\"\"Imprime o texto e reproduz o √°udio.\"\"\"\n",
    "        print(f\"ü§ñ Assistente: {text}\")\n",
    "        try:\n",
    "            self._engine.say(text)\n",
    "            self._engine.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro ao emitir som: {e}\")\n",
    "\n",
    "class SilentTTS:\n",
    "    \"\"\"Apenas imprime as respostas, sem emitir som.\"\"\"\n",
    "    def speak(self, text: str) -> None:\n",
    "        print(f\"ü§ñ Assistente (Modo Silencioso): {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai_md",
   "metadata": {},
   "source": [
    "## üß† Passo 6: Integra√ß√£o com Intelig√™ncia Artificial\n",
    "\n",
    "Conectamos o assistente ao modelo **GLM-4.7-Flash**. Esta fun√ß√£o inclui l√≥gica de retentativa para garantir robustez contra falhas tempor√°rias de rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ai_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glm_response(text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Envia o texto para a API da IA e retorna a resposta gerada.\n",
    "    Inclui 3 tentativas em caso de erro de timeout ou servidor.\n",
    "    \"\"\"\n",
    "    max_retries = 3\n",
    "    retry_delay = 2\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from openai import OpenAI\n",
    "            \n",
    "            # Recupera o token do arquivo .env\n",
    "            hf_token = os.getenv(\"HF_TOKEN\")\n",
    "            if not hf_token or hf_token == \"seu_token_hf_aqui\":\n",
    "                return \"‚ö†Ô∏è Erro: HF_TOKEN n√£o configurado no arquivo .env.\"\n",
    "                \n",
    "            # Configura o cliente para o Router do Hugging Face\n",
    "            client = OpenAI(\n",
    "                base_url=\"https://router.huggingface.co/v1\",\n",
    "                api_key=hf_token,\n",
    "                timeout=30.0\n",
    "            )\n",
    "            \n",
    "            # Chamada de chat completion\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"zai-org/GLM-4.7-Flash\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente virtual prestativo e conciso. Responda em portugu√™s brasileiro.\"},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            # Verifica se √© um erro que vale a pena tentar de novo (502, 503, 504, Timeout)\n",
    "            if any(code in error_str for code in [\"504\", \"502\", \"503\", \"timeout\"]) and attempt < max_retries - 1:\n",
    "                print(f\"‚ö†Ô∏è Falha na conex√£o com a IA. Tentando novamente em {retry_delay}s... (Tentativa {attempt + 1})\")\n",
    "                time.sleep(retry_delay * (attempt + 1))\n",
    "                continue\n",
    "            \n",
    "            # Trata erros espec√≠ficos de infraestrutura (respostas HTML)\n",
    "            if \"<!DOCTYPE html>\" in error_str or \"<html>\" in error_str:\n",
    "                return \"‚ùå O servidor de IA est√° inst√°vel no momento. Por favor, tente novamente mais tarde.\"\n",
    "                \n",
    "            return f\"‚ùå Erro t√©cnico na IA: {error_str}\"\n",
    "            \n",
    "    return \"‚ùå Falha definitiva ap√≥s m√∫ltiplas tentativas de conex√£o.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actions_md",
   "metadata": {},
   "source": [
    "## ‚ö° Passo 7: Processamento de Comandos e A√ß√µes\n",
    "\n",
    "Aqui definimos a l√≥gica que decide se o comando do usu√°rio √© um atalho local (abrir site, pesquisar) ou se deve ser enviado para a IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "actions",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ActionResult:\n",
    "    \"\"\"Classe simples para armazenar o resultado de uma execu√ß√£o de comando.\"\"\"\n",
    "    success: bool\n",
    "    message: str\n",
    "    is_ai: bool = False\n",
    "\n",
    "def parse_and_execute(text: str) -> ActionResult:\n",
    "    \"\"\"\n",
    "    Analisa a string de entrada e executa a a√ß√£o correspondente.\n",
    "    Prioriza comandos locais antes de enviar para a IA.\n",
    "    \"\"\"\n",
    "    s = (text or \"\").lower().strip()\n",
    "    if not s: return ActionResult(False, \"N√£o entendi o que voc√™ disse.\")\n",
    "    \n",
    "    # --- COMANDOS LOCAIS ---\n",
    "    \n",
    "    # A√ß√£o: Pesquisar na Wikipedia\n",
    "    if \"wikipedia\" in s:\n",
    "        q = s.replace(\"wikipedia\", \"\").replace(\"pesquisar\", \"\").strip()\n",
    "        url = \"https://pt.wikipedia.org/wiki/Special:Search?search=\" + urllib.parse.quote_plus(q)\n",
    "        webbrowser.open(url)\n",
    "        return ActionResult(True, f\"Pesquisando sobre '{q}' na Wikipedia.\")\n",
    "        \n",
    "    # A√ß√£o: Pesquisar no YouTube\n",
    "    if \"youtube\" in s or \"video\" in s:\n",
    "        q = s.replace(\"youtube\", \"\").replace(\"video\", \"\").replace(\"pesquisar\", \"\").strip()\n",
    "        url = \"https://www.youtube.com/results?search_query=\" + urllib.parse.quote_plus(q)\n",
    "        webbrowser.open(url)\n",
    "        return ActionResult(True, f\"Buscando v√≠deos sobre '{q}' no YouTube.\")\n",
    "        \n",
    "    # A√ß√£o: Buscar farm√°cia pr√≥xima\n",
    "    if \"farm√°cia\" in s or \"farmacia\" in s:\n",
    "        webbrowser.open(\"https://www.google.com/maps/search/farmacia+perto+de+mim\")\n",
    "        return ActionResult(True, \"Abrindo o mapa com as farm√°cias mais pr√≥ximas.\")\n",
    "    \n",
    "    # --- PROCESSAMENTO VIA IA ---\n",
    "    # Se nenhum comando local foi detectado, pergunta ao GLM-4\n",
    "    print(\"üîç Consultando a intelig√™ncia artificial...\")\n",
    "    ai_response = get_glm_response(text)\n",
    "    \n",
    "    if ai_response:\n",
    "        return ActionResult(True, ai_response, is_ai=True)\n",
    "        \n",
    "    return ActionResult(False, \"Desculpe, n√£o consegui processar seu pedido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orchestrator_md",
   "metadata": {},
   "source": [
    "## üïπÔ∏è Passo 8: Classe Orquestradora do Assistente\n",
    "\n",
    "Esta classe gerencia o ciclo de vida do assistente: ouvir o usu√°rio, processar a inten√ß√£o e responder via √°udio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "orchestrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    \"\"\"Gerenciador principal do fluxo de conversa√ß√£o do assistente virtual.\"\"\"\n",
    "    def __init__(self, stt: SpeechToText, tts: TextToSpeech):\n",
    "        \"\"\"\n",
    "        Injeta as depend√™ncias de Voz e Fala.\n",
    "        :param stt: Inst√¢ncia de um provedor de fala-para-texto\n",
    "        :param tts: Inst√¢ncia de um provedor de texto-para-fala\n",
    "        \"\"\"\n",
    "        self._stt = stt\n",
    "        self._tts = tts\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Inicia o loop infinito de intera√ß√£o.\"\"\"\n",
    "        self._tts.speak(\"Ol√°! Sou seu assistente virtual inteligente. Como posso ajudar voc√™ hoje?\")\n",
    "        \n",
    "        while True:\n",
    "            # 1. Escuta a entrada do usu√°rio\n",
    "            text = self._stt.listen()\n",
    "            if not text: continue\n",
    "            \n",
    "            print(f\"üë§ Usu√°rio: {text}\")\n",
    "            \n",
    "            # 2. Verifica se o usu√°rio quer encerrar o programa\n",
    "            if text.lower().strip() in [\"sair\", \"encerrar\", \"tchau\", \"finalizar\", \"adeus\"]:\n",
    "                self._tts.speak(\"Entendido. Encerrando o sistema. At√© logo!\")\n",
    "                break\n",
    "                \n",
    "            # 3. Processa o comando (Local ou IA)\n",
    "            result = parse_and_execute(text)\n",
    "            \n",
    "            # 4. Responde via √°udio e texto\n",
    "            self._tts.speak(result.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_md",
   "metadata": {},
   "source": [
    "## üöÄ Passo 9: Inicializa√ß√£o e Execu√ß√£o\n",
    "\n",
    "Agora, configuramos as implementa√ß√µes que queremos usar (Voz vs Teclado) e iniciamos o assistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "run_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistente: Ol√°! Sou seu assistente virtual inteligente. Como posso ajudar voc√™ hoje?\n",
      "üë§ Usu√°rio: oi\n",
      "üîç Consultando a intelig√™ncia artificial...\n",
      "ü§ñ Assistente: Ol√°! Como posso ajudar voc√™ hoje?\n",
      "üë§ Usu√°rio: sair\n",
      "ü§ñ Assistente: Entendido. Encerrando o sistema. At√© logo!\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o dos componentes para o Notebook\n",
    "\n",
    "# Recomendado para Notebook: Entrada via teclado (TextInputSTT)\n",
    "# Para usar microfone, descomente a linha do WhisperSTT abaixo e comente a do TextInputSTT\n",
    "stt = TextInputSTT()\n",
    "# stt = WhisperSTT(duration=5)\n",
    "\n",
    "try:\n",
    "    # Tenta carregar o motor de voz local\n",
    "    tts = Pyttsx3TTS()\n",
    "except Exception as e:\n",
    "    # Se o sistema n√£o tiver suporte a som, usa o modo silencioso (apenas texto)\n",
    "    print(f\"‚ö†Ô∏è Aviso: N√£o foi poss√≠vel iniciar o motor de voz ({e}). Usando modo silencioso.\")\n",
    "    tts = SilentTTS()\n",
    "\n",
    "# Instancia e executa o assistente\n",
    "assistant = Assistant(stt, tts)\n",
    "assistant.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
